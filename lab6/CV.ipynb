{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morhunenko Mykola lab6 CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After 3-4 trying I desided to make a marging for the second image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ = cv2.imread('stitching/1.jpg')\n",
    "img = cv2.imread('stitching/2.jpg')\n",
    "\n",
    "ht1, wd1, cc1= img_.shape\n",
    "ht2, wd2, cc2= img.shape\n",
    "color = (0,0,0)\n",
    "result = np.full((555,wd1 + wd2,cc1), color, dtype=np.uint8)\n",
    "result[0:ht2, wd1:wd1 + wd2] = img\n",
    "# plt.imshow(result)\n",
    "img = result\n",
    "\n",
    "img1 = cv2.cvtColor(img_,cv2.COLOR_BGR2GRAY)\n",
    "img2 = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BRISK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brisk = cv2.BRISK_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1, des1 = brisk.detectAndCompute(img1,None)\n",
    "kp2, des2 = brisk.detectAndCompute(img2,None)\n",
    "\n",
    "i1 = cv2.drawKeypoints(img1, kp1, None, color=(0,255,0), flags=0)\n",
    "i2 = cv2.drawKeypoints(img2, kp2, None, color=(0,255,0), flags=0)\n",
    "plt.imshow(i1), plt.show()\n",
    "plt.imshow(i2), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True) \n",
    "matches = matcher.match(des2,des1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "final_img = cv2.drawMatches(img, kp2,img_, kp1, matches,None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,30))\n",
    "plt.imshow(final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pts = np.float32([ kp2[m.queryIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "\n",
    "dst_pts = np.float32([ kp1[m.trainIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "\n",
    "M, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I don\\`t know for sure what does each entry means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w = img1.shape\n",
    "pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "dst = cv2.perspectiveTransform(pts, M)\n",
    "img1 = cv2.polylines(img1,[np.int32(dst)],True,255,3, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = np.full((img.shape[1] + img_.shape[1],img_.shape[0],cc1), color, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.warpPerspective(img_,M,(img.shape[1] + img_.shape[1], img_.shape[0]))\n",
    "# dst[0:img.shape[0],0:img.shape[1]] = img\n",
    "plt.figure(figsize = (30,30))\n",
    "plt.imshow(dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we get the scaled and warped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trim(frame):\n",
    "    if not np.sum(frame[0]):\n",
    "        return trim(frame[1:])\n",
    "    if not np.sum(frame[-1]):\n",
    "        return trim(frame[:-2])\n",
    "    if not np.sum(frame[:,0]):\n",
    "        return trim(frame[:,1:])\n",
    "    if not np.sum(frame[:,-1]):\n",
    "        return trim(frame[:,:-2])\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = dst[0:dst.shape[0], 0:img.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As far as I don't know all that AI stuff, I found the next way to add two images (because of that marging they can not easily overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(dst)\n",
    "plt.figure(figsize = (30,30))\n",
    "# img = cv2.bitwise_xor(img, dst)\n",
    "added_image = cv2.addWeighted(img,1,dst,0.5,1)\n",
    "plt.imshow(added_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"added.jpg\", added_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
