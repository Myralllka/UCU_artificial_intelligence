{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"part1b_pretrained_descriptor.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"eOnDHTpOVOeO","executionInfo":{"status":"ok","timestamp":1601813813022,"user_tz":-180,"elapsed":648,"user":{"displayName":"Микола Моргуненко","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTrcLfxO2G7xx7VBfvL-n-hTKmibz_GMTpt1yF=s64","userId":"04777179242882632176"}}},"source":["from torch import nn\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","\n","import numpy as np\n","from numpy import loadtxt\n","from PIL import Image\n","from scipy.spatial.distance import cdist\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as functional"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"-xe5_fTTVpq6","executionInfo":{"status":"ok","timestamp":1601810833395,"user_tz":-180,"elapsed":838,"user":{"displayName":"Микола Моргуненко","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTrcLfxO2G7xx7VBfvL-n-hTKmibz_GMTpt1yF=s64","userId":"04777179242882632176"}},"outputId":"a903064f-4c28-4cd5-d02e-14099bc09caa","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# from google.colab import drive\n","# drive.mount(\"/content/drive/\")\n","# !cd drive/My\\ Drive/Artificial\\ intelligence/lab3/\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["drive  sample_data\n","drive  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X6RVLKMUVOeS"},"source":["def cub_subset(n = 4):\n","    \"\"\"\n","    Function to read subset of birds dataset CUB_200_2011\n","    n : n images per class\n","    \"\"\"\n","    cub_folder = 'drive/My Drive/Artificial intelligence/lab3/vs3ex1data/CUB_200_2011/'\n","    f = open(cub_folder + \"images.txt\", 'r')\n","    cub_imgfn = [a.split(' ')[::-1] for a in f.read().split('\\n')]\n","    cub_label = loadtxt(cub_folder + \"image_class_labels.txt\", delimiter=\" \", unpack=False)[:,1].astype(int) - 1\n","    sub_idx = []\n","    for i in range(0,max(cub_label)+1):\n","        sub_idx = sub_idx + ([x for (x,val) in enumerate(cub_label) if val == i][0:n])\n","        \n","    cub_img = [(cub_folder+'/jpg/'+cub_imgfn[x][0]) for x in sub_idx]\n","    cub_label = np.array([cub_label[x] for x in sub_idx])\n","    \n","    return cub_img, cub_label\n","\n","\n","# get images and labels for CUB subset\n","cub_img, cub_label = cub_subset()\n","\n","# show sample images\n","for i in range(0,200,20):\n","    plt.imshow(Image.open(cub_img[i]))\n","    plt.show\n","    plt.pause(0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvJFJWQaVOeZ","executionInfo":{"status":"ok","timestamp":1601812008771,"user_tz":-180,"elapsed":3505,"user":{"displayName":"Микола Моргуненко","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTrcLfxO2G7xx7VBfvL-n-hTKmibz_GMTpt1yF=s64","userId":"04777179242882632176"}},"outputId":"4ebaeff1-5983-4392-b5a5-1a584e8abc37","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["def test(descriptors, labels):\n","    \"\"\"\n","    Evaluate descriptors on retrieval\n","    \"\"\"\n","    # compute all pair-wise distances\n","    cdistances = cdist(descriptors.data.numpy(), descriptors.data.numpy(), 'euclidean')\n","\n","    # find rank of closest positive image (using each descriptor as a query)\n","    minrank_positive = []\n","    for i in range(0,len(cdistances)):\n","        idx = np.argsort(cdistances[i])\n","        minrank_positive.append( np.min([j for (j,x) in enumerate(labels[idx[1:-1]]) if x==labels[i]]) )\n","\n","    print('At-least-1-positive@1   : {:.3f}'.format((np.array(minrank_positive)<1).mean()))\n","    print('At-least-1-positive@5   : {:.3f}'.format((np.array(minrank_positive)<5).mean()))\n","    print('At-least-1-positive@10  : {:.3f}'.format((np.array(minrank_positive)<10).mean()))\n","\n","# evaluate the descriptors in a retrieval task \n","test(des, cub_label)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["At-least-1-positive@1   : 0.141\n","At-least-1-positive@5   : 0.354\n","At-least-1-positive@10  : 0.453\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"QNZjUw10VOeW"},"source":["def l2n(x, eps=1e-6):\n","    \"\"\"\n","    Vector L2 normalization \n","    \"\"\"\n","    return x / (torch.norm(x, p=2, dim=1, keepdim=True) + eps).expand_as(x)\n","\n","class EmbNet(nn.Module):\n","    \"\"\"\n","    Create network that maps an image to an embedding (descriptor) \n","    \"\"\"    \n","    def __init__(self, input_net, n = 3):\n","        \"\"\"\n","        Contructor takes another network (input_net) as input\n","        input_net: assumed to have features and classifier fields (eg AlexNet, VGG, ...)\n","        n: keep unitl n-th layer of the classifier \n","        \"\"\"\n","        super(EmbNet, self).__init__()\n","        self.features = input_net.features\n","        self.classifier = nn.Sequential(*list(input_net.classifier[0:n+1]));  # keep until n-th layer\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), x.size(1)*x.size(2)*x.size(3))\n","        x = self.classifier(x)\n","        return l2n(x)\n","\n","model = torchvision.models.alexnet(pretrained = True) # load pre-trained model\n","print(model)\n","\n","# image transformation \n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n","scale = transforms.Resize([224,224])\n","tote = transforms.ToTensor()\n","comptran = transforms.Compose([scale,tote,normalize])\n","\n","last_layer = 1  # of the classifier part\n","getdescriptor = EmbNet(model, last_layer) # construct the network that extracts descriptors \n","getdescriptor.eval()   # put network in evaluation mode\n","print(getdescriptor)\n","\n","# extact descriptors for all images\n","print('Extracting descriptors...')\n","des = torch.Tensor()\n","for i in range(0, len(cub_img)):\n","    with torch.no_grad():\n","        des = torch.cat((des, getdescriptor((comptran(Image.open(cub_img[i])).unsqueeze(0)))))\n","print('Finished with extracting descriptors...')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1gIoVL0heYR","executionInfo":{"status":"ok","timestamp":1601813713572,"user_tz":-180,"elapsed":239170,"user":{"displayName":"Микола Моргуненко","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTrcLfxO2G7xx7VBfvL-n-hTKmibz_GMTpt1yF=s64","userId":"04777179242882632176"}},"outputId":"d9409e3d-f1b3-41dd-b12f-2524b67a8b45","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for last_layer in range(1, 6):\n","    print(f'############# Iteration with last_layer={last_layer} ############# ')\n","\n","    # last_layer = 1  # of the classifier part\n","    getdescriptor = EmbNet(model, last_layer) # construct the network that extracts descriptors\n","    getdescriptor.eval()   # put network in evaluation mode\n","    print(getdescriptor)\n","\n","    # extract descriptors for all images\n","    print('Extracting descriptors...')\n","    des = torch.Tensor()\n","    for i in range(0, len(cub_img)):\n","        with torch.no_grad():\n","            des = torch.cat((des, getdescriptor((comptran(Image.open(cub_img[i])).unsqueeze(0)))))\n","    print('Finished with extracting descriptors...')\n","\n","    # evaluate the descriptors in a retrieval task\n","    test(des, cub_label)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["############# Iteration with last_layer=1 ############# \n","EmbNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","  )\n",")\n","Extracting descriptors...\n","Finished with extracting descriptors...\n","At-least-1-positive@1   : 0.141\n","At-least-1-positive@5   : 0.354\n","At-least-1-positive@10  : 0.453\n","############# Iteration with last_layer=2 ############# \n","EmbNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","  )\n",")\n","Extracting descriptors...\n","Finished with extracting descriptors...\n","At-least-1-positive@1   : 0.159\n","At-least-1-positive@5   : 0.366\n","At-least-1-positive@10  : 0.468\n","############# Iteration with last_layer=3 ############# \n","EmbNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Extracting descriptors...\n","Finished with extracting descriptors...\n","At-least-1-positive@1   : 0.159\n","At-least-1-positive@5   : 0.366\n","At-least-1-positive@10  : 0.468\n","############# Iteration with last_layer=4 ############# \n","EmbNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=4096, out_features=4096, bias=True)\n","  )\n",")\n","Extracting descriptors...\n","Finished with extracting descriptors...\n","At-least-1-positive@1   : 0.150\n","At-least-1-positive@5   : 0.344\n","At-least-1-positive@10  : 0.458\n","############# Iteration with last_layer=5 ############# \n","EmbNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=4096, out_features=4096, bias=True)\n","    (5): ReLU(inplace=True)\n","  )\n",")\n","Extracting descriptors...\n","Finished with extracting descriptors...\n","At-least-1-positive@1   : 0.160\n","At-least-1-positive@5   : 0.365\n","At-least-1-positive@10  : 0.477\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NQ1ROUdTVOec","executionInfo":{"status":"ok","timestamp":1601814008138,"user_tz":-180,"elapsed":32247,"user":{"displayName":"Микола Моргуненко","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTrcLfxO2G7xx7VBfvL-n-hTKmibz_GMTpt1yF=s64","userId":"04777179242882632176"}},"outputId":"c12e9d89-69a0-43e8-e741-48bb16b5040e","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["class EmbNetGP(nn.Module):\n","    \"\"\"\n","    Create network that maps an image to an embedding (descriptor) with global pooling\n","    \"\"\"    \n","    def __init__(self, input_net):\n","        \"\"\"\n","        Contructor takes another network (input_net) as input\n","        input_net: assumed to have features and classifier fields (eg AlexNet, VGG, ...)\n","        n: keep unitl n-th layer of the classifier \n","        \"\"\"\n","        \n","        ### YOUR CODE HERE\n","        super(EmbNetGP, self).__init__()\n","        self.features = input_net.features\n","        self.pool = nn.MaxPool2d(5)\n","\n","\n","    def forward(self, x):\n","        ### YOUR CODE HERE\n","        x = self.features(x)\n","        x = self.pool(functional.relu(x))\n","        x = x.view(x.size(0), x.size(1)*x.size(2)*x.size(3))\n","        return l2n(x)\n","\n","\n","    \n","getdescriptor = EmbNetGP(model) # construct the network that extracts descriptors \n","getdescriptor.eval()   # put network in evaluation mode\n","\n","# extact descriptors for all images\n","print('Extracting descriptors...')\n","des = torch.Tensor()\n","for i in range(0, len(cub_img)):\n","    with torch.no_grad():\n","        des = torch.cat((des, getdescriptor((comptran(Image.open(cub_img[i])).unsqueeze(0)))))\n","print('Finished with extracting descriptors...')\n","\n","# evaluate the descriptors in a retrieval task \n","test(des, cub_label)    "],"execution_count":29,"outputs":[{"output_type":"stream","text":["Extracting descriptors...\n","Finished with extracting descriptors...\n","At-least-1-positive@1   : 0.199\n","At-least-1-positive@5   : 0.430\n","At-least-1-positive@10  : 0.540\n"],"name":"stdout"}]}]}