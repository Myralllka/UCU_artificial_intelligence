{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1601813813022,
     "user": {
      "displayName": "Микола Моргуненко",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTrcLfxO2G7xx7VBfvL-n-hTKmibz_GMTpt1yF=s64",
      "userId": "04777179242882632176"
     },
     "user_tz": -180
    },
    "id": "eOnDHTpOVOeO"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 838,
     "status": "ok",
     "timestamp": 1601810833395,
     "user": {
      "displayName": "Микола Моргуненко",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTrcLfxO2G7xx7VBfvL-n-hTKmibz_GMTpt1yF=s64",
      "userId": "04777179242882632176"
     },
     "user_tz": -180
    },
    "id": "-xe5_fTTVpq6",
    "outputId": "a903064f-4c28-4cd5-d02e-14099bc09caa"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive/\")\n",
    "# !cd drive/My\\ Drive/Artificial\\ intelligence/lab3/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6RVLKMUVOeS"
   },
   "outputs": [],
   "source": [
    "def cub_subset(n = 4):\n",
    "    \"\"\"\n",
    "    Function to read subset of birds dataset CUB_200_2011\n",
    "    n : n images per class\n",
    "    \"\"\"\n",
    "    cub_folder = 'drive/My Drive/Artificial intelligence/lab3/vs3ex1data/CUB_200_2011/'\n",
    "    f = open(cub_folder + \"images.txt\", 'r')\n",
    "    cub_imgfn = [a.split(' ')[::-1] for a in f.read().split('\\n')]\n",
    "    cub_label = loadtxt(cub_folder + \"image_class_labels.txt\", delimiter=\" \", unpack=False)[:,1].astype(int) - 1\n",
    "    sub_idx = []\n",
    "    for i in range(0,max(cub_label)+1):\n",
    "        sub_idx = sub_idx + ([x for (x,val) in enumerate(cub_label) if val == i][0:n])\n",
    "        \n",
    "    cub_img = [(cub_folder+'/jpg/'+cub_imgfn[x][0]) for x in sub_idx]\n",
    "    cub_label = np.array([cub_label[x] for x in sub_idx])\n",
    "    \n",
    "    return cub_img, cub_label\n",
    "\n",
    "\n",
    "# get images and labels for CUB subset\n",
    "cub_img, cub_label = cub_subset()\n",
    "\n",
    "# show sample images\n",
    "for i in range(0,200,20):\n",
    "    plt.imshow(Image.open(cub_img[i]))\n",
    "    plt.show\n",
    "    plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 3505,
     "status": "ok",
     "timestamp": 1601812008771,
     "user": {
      "displayName": "Микола Моргуненко",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTrcLfxO2G7xx7VBfvL-n-hTKmibz_GMTpt1yF=s64",
      "userId": "04777179242882632176"
     },
     "user_tz": -180
    },
    "id": "SvJFJWQaVOeZ",
    "outputId": "4ebaeff1-5983-4392-b5a5-1a584e8abc37"
   },
   "outputs": [],
   "source": [
    "def test(descriptors, labels):\n",
    "    \"\"\"\n",
    "    Evaluate descriptors on retrieval\n",
    "    \"\"\"\n",
    "    # compute all pair-wise distances\n",
    "    cdistances = cdist(descriptors.data.numpy(), descriptors.data.numpy(), 'euclidean')\n",
    "\n",
    "    # find rank of closest positive image (using each descriptor as a query)\n",
    "    minrank_positive = []\n",
    "    for i in range(0,len(cdistances)):\n",
    "        idx = np.argsort(cdistances[i])\n",
    "        minrank_positive.append( np.min([j for (j,x) in enumerate(labels[idx[1:-1]]) if x==labels[i]]) )\n",
    "\n",
    "    print('At-least-1-positive@1   : {:.3f}'.format((np.array(minrank_positive)<1).mean()))\n",
    "    print('At-least-1-positive@5   : {:.3f}'.format((np.array(minrank_positive)<5).mean()))\n",
    "    print('At-least-1-positive@10  : {:.3f}'.format((np.array(minrank_positive)<10).mean()))\n",
    "\n",
    "# evaluate the descriptors in a retrieval task \n",
    "test(des, cub_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNZjUw10VOeW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def l2n(x, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Vector L2 normalization \n",
    "    \"\"\"\n",
    "    return x / (torch.norm(x, p=2, dim=1, keepdim=True) + eps).expand_as(x)\n",
    "\n",
    "class EmbNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Create network that maps an image to an embedding (descriptor) \n",
    "    \"\"\"    \n",
    "    def __init__(self, input_net, n = 3):\n",
    "        \"\"\"\n",
    "        Contructor takes another network (input_net) as input\n",
    "        input_net: assumed to have features and classifier fields (eg AlexNet, VGG, ...)\n",
    "        n: keep unitl n-th layer of the classifier \n",
    "        \"\"\"\n",
    "        super(EmbNet, self).__init__()\n",
    "        self.features = input_net.features\n",
    "        self.classifier = nn.Sequential(*list(input_net.classifier[0:n+1]));  # keep until n-th layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), x.size(1)*x.size(2)*x.size(3))\n",
    "        x = self.classifier(x)\n",
    "        return l2n(x)\n",
    "\n",
    "model = torchvision.models.alexnet(pretrained = True) # load pre-trained model\n",
    "print(model)\n",
    "\n",
    "# image transformation \n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "scale = transforms.Resize([224,224])\n",
    "tote = transforms.ToTensor()\n",
    "comptran = transforms.Compose([scale,tote,normalize])\n",
    "\n",
    "last_layer = 1  # of the classifier part\n",
    "getdescriptor = EmbNet(model, last_layer) # construct the network that extracts descriptors \n",
    "getdescriptor.eval()   # put network in evaluation mode\n",
    "print(getdescriptor)\n",
    "\n",
    "# extact descriptors for all images\n",
    "print('Extracting descriptors...')\n",
    "des = torch.Tensor()\n",
    "for i in range(0, len(cub_img)):\n",
    "    with torch.no_grad():\n",
    "        des = torch.cat((des, getdescriptor((comptran(Image.open(cub_img[i])).unsqueeze(0)))))\n",
    "print('Finished with extracting descriptors...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 239170,
     "status": "ok",
     "timestamp": 1601813713572,
     "user": {
      "displayName": "Микола Моргуненко",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTrcLfxO2G7xx7VBfvL-n-hTKmibz_GMTpt1yF=s64",
      "userId": "04777179242882632176"
     },
     "user_tz": -180
    },
    "id": "N1gIoVL0heYR",
    "outputId": "d9409e3d-f1b3-41dd-b12f-2524b67a8b45"
   },
   "outputs": [],
   "source": [
    "for last_layer in range(1, 6):\n",
    "    print(f'############# Iteration with last_layer={last_layer} ############# ')\n",
    "\n",
    "    # last_layer = 1  # of the classifier part\n",
    "    getdescriptor = EmbNet(model, last_layer) # construct the network that extracts descriptors\n",
    "    getdescriptor.eval()   # put network in evaluation mode\n",
    "    print(getdescriptor)\n",
    "\n",
    "    # extract descriptors for all images\n",
    "    print('Extracting descriptors...')\n",
    "    des = torch.Tensor()\n",
    "    for i in range(0, len(cub_img)):\n",
    "        with torch.no_grad():\n",
    "            des = torch.cat((des, getdescriptor((comptran(Image.open(cub_img[i])).unsqueeze(0)))))\n",
    "    print('Finished with extracting descriptors...')\n",
    "\n",
    "    # evaluate the descriptors in a retrieval task\n",
    "    test(des, cub_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "executionInfo": {
     "elapsed": 32247,
     "status": "ok",
     "timestamp": 1601814008138,
     "user": {
      "displayName": "Микола Моргуненко",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTrcLfxO2G7xx7VBfvL-n-hTKmibz_GMTpt1yF=s64",
      "userId": "04777179242882632176"
     },
     "user_tz": -180
    },
    "id": "NQ1ROUdTVOec",
    "outputId": "c12e9d89-69a0-43e8-e741-48bb16b5040e"
   },
   "outputs": [],
   "source": [
    "class EmbNetGP(nn.Module):\n",
    "    \"\"\"\n",
    "    Create network that maps an image to an embedding (descriptor) with global pooling\n",
    "    \"\"\"    \n",
    "    def __init__(self, input_net):\n",
    "        \"\"\"\n",
    "        Contructor takes another network (input_net) as input\n",
    "        input_net: assumed to have features and classifier fields (eg AlexNet, VGG, ...)\n",
    "        n: keep unitl n-th layer of the classifier \n",
    "        \"\"\"\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        super(EmbNetGP, self).__init__()\n",
    "        self.features = input_net.features\n",
    "        self.pool = nn.MaxPool2d(5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### YOUR CODE HERE\n",
    "        x = self.features(x)\n",
    "        x = self.pool(functional.relu(x))\n",
    "        x = x.view(x.size(0), x.size(1)*x.size(2)*x.size(3))\n",
    "        return l2n(x)\n",
    "\n",
    "\n",
    "    \n",
    "getdescriptor = EmbNetGP(model) # construct the network that extracts descriptors \n",
    "getdescriptor.eval()   # put network in evaluation mode\n",
    "\n",
    "# extact descriptors for all images\n",
    "print('Extracting descriptors...')\n",
    "des = torch.Tensor()\n",
    "for i in range(0, len(cub_img)):\n",
    "    with torch.no_grad():\n",
    "        des = torch.cat((des, getdescriptor((comptran(Image.open(cub_img[i])).unsqueeze(0)))))\n",
    "print('Finished with extracting descriptors...')\n",
    "\n",
    "# evaluate the descriptors in a retrieval task \n",
    "test(des, cub_label)    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "part1b_pretrained_descriptor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
