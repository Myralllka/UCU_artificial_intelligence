{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1601837293608,
     "user": {
      "displayName": "Микола Моргуненко",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTrcLfxO2G7xx7VBfvL-n-hTKmibz_GMTpt1yF=s64",
      "userId": "04777179242882632176"
     },
     "user_tz": -180
    },
    "id": "xjcNLq3xkIKP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1601837293609,
     "user": {
      "displayName": "Микола Моргуненко",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTrcLfxO2G7xx7VBfvL-n-hTKmibz_GMTpt1yF=s64",
      "userId": "04777179242882632176"
     },
     "user_tz": -180
    },
    "id": "gVYS3S-UkQBf"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive/\")\n",
    "\n",
    "path = 'drive/My Drive/Artificial intelligence/lab3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1601837293609,
     "user": {
      "displayName": "Микола Моргуненко",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTrcLfxO2G7xx7VBfvL-n-hTKmibz_GMTpt1yF=s64",
      "userId": "04777179242882632176"
     },
     "user_tz": -180
    },
    "id": "p9QgvvR5kIKV"
   },
   "outputs": [],
   "source": [
    "class MnistNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Liteweight network architecture for the Mnist dataset (digit) classification\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MnistNet, self).__init__()\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        # fully convolutional part\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=5),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(4, 4, kernel_size=5),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(inplace=True)  \n",
    "        )\n",
    "        \n",
    "        # classifier, FC layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*4,16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(16,self.num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x.view(-1,x.size(-3)*x.size(-2)*x.size(-1)))\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer):\n",
    "    \"\"\"\n",
    "    Training of an epoch\n",
    "    model: network\n",
    "    train_loader: train_loader loading images and labels in batches\n",
    "    optimizer: optimizer to use in the training\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad() # zero the accumulated gradients\n",
    "        output = model(data) # computer network's output\n",
    "        loss = F.cross_entropy(output, target) # computer the loss\n",
    "        loss.backward() # backward pass\n",
    "        optimizer.step() # update weights\n",
    "        \n",
    "        total_loss = total_loss + loss.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('[{}/{} ({:.0f}%)]\\tBatch loss: {:.6f}'.format(\n",
    "                batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()/len(data)))\n",
    "    \n",
    "    print('Training: Epoch average loss {:.6f}'.format(total_loss/len(train_loader.dataset)))\n",
    "         \n",
    "        \n",
    "def test(model, val_loader):\n",
    "    \"\"\"\n",
    "    Compute accuracy on the validation set\n",
    "    model: network\n",
    "    val_loader: test_loader loading images and labels in batches\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # implement validation procedure, report accuracy on the validation set\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    test_losses = []\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "      for data, target in val_loader:\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(val_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(val_loader.dataset), 100. * correct / len(val_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1111,
     "status": "ok",
     "timestamp": 1601837294706,
     "user": {
      "displayName": "Микола Моргуненко",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTrcLfxO2G7xx7VBfvL-n-hTKmibz_GMTpt1yF=s64",
      "userId": "04777179242882632176"
     },
     "user_tz": -180
    },
    "id": "uBvjEP6kkIKZ",
    "outputId": "82dd1a7a-a16c-40dc-a047-0b710de27359"
   },
   "outputs": [],
   "source": [
    "# mnist dataset structure - train part\n",
    "mnist_dataset_train = datasets.MNIST(path + 'drive/My Drive/Artificial intelligence/lab3/vs3ex1data/mnist_data', train=True, download=True, transform=transforms.Compose([\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize((0.1307,), (0.3081,))\n",
    "               ]))\n",
    "# mnist dataset structure - test part\n",
    "mnist_dataset_val = datasets.MNIST('drive/My Drive/Artificial intelligence/lab3/vs3ex1data/mnist_data', train=False, download=True, transform=transforms.Compose([\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize((0.1307,), (0.3081,))\n",
    "               ]))\n",
    "mnist_dataset_val\n",
    "# show sample images\n",
    "print('Sample images')\n",
    "for i in range(0,100,10):\n",
    "    plt.imshow(Image.fromarray(mnist_dataset_train.train_data[i].numpy(), mode='L'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 388764,
     "status": "ok",
     "timestamp": 1601837293606,
     "user": {
      "displayName": "Микола Моргуненко",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhTrcLfxO2G7xx7VBfvL-n-hTKmibz_GMTpt1yF=s64",
      "userId": "04777179242882632176"
     },
     "user_tz": -180
    },
    "id": "14ITw6qakIKc",
    "outputId": "b9cc13eb-1dd2-4de6-93fc-d55fcd14e0ea"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# loader of the training set\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dataset_train,batch_size=16, shuffle=True)\n",
    "# loader of the validation set\n",
    "val_loader = torch.utils.data.DataLoader(mnist_dataset_val,batch_size=512, shuffle=False)\n",
    "\n",
    "model = MnistNet() # initialize network structure\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "for epoch in range(1, 20 + 1):\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        train(model, train_loader, optimizer)\n",
    "        test(model, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ilwfz8U91BaY"
   },
   "source": [
    "By adding Batch Normalizations and one dropout layer after convolutions I increase the Accuracy on 2-3% in average (from 95% to 98%)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "part2a_train_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
